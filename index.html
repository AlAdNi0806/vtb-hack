<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Real-time Streaming ASR Frontend</title>
<style>
  #transcript {
    border: 1px solid #ccc;
    padding: 10px;
    min-height: 100px;
    white-space: pre-wrap;
  }
  button {
    padding: 10px 20px;
    font-size: 1.2em;
  }
</style>
</head>
<body>
<h1>Realtime Speech-to-Text</h1>
<button id="startStopBtn">Start Recording</button>
<div id="transcript" placeholder="Transcription appears here..."></div>

<script>
const startStopBtn = document.getElementById('startStopBtn');
const transcriptDiv = document.getElementById('transcript');

let audioCtx;
let source;
let processor;
let socket;
let recognizing = false;

startStopBtn.onclick = async () => {
  if (!recognizing) {
    const stream = await navigator.mediaDevices.getUserMedia({audio: true});
    // DO NOT pass sampleRate here
    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    source = audioCtx.createMediaStreamSource(stream);

    const targetRate = 16000;
    const downsampleRatio = audioCtx.sampleRate / targetRate;

    processor = audioCtx.createScriptProcessor(4096, 1, 1);
    const ws = new WebSocket('ws://192.168.0.176:8765');

    processor.onaudioprocess = e => {
      const input = e.inputBuffer.getChannelData(0);
      const downsampledLen = Math.floor(input.length / downsampleRatio);
      const pcm16 = new Int16Array(downsampledLen);

      for (let i = 0; i < downsampledLen; i++) {
        const src = Math.floor(i * downsampleRatio);
        pcm16[i] = Math.max(-1, Math.min(1, input[src])) * 0x7FFF;
      }

      if (ws.readyState === WebSocket.OPEN) {
        ws.send(pcm16.buffer);
      }
    };

    ws.onopen = () => {
      source.connect(processor);
      processor.connect(audioCtx.destination); // needed for ScriptProcessor
      startStopBtn.textContent = 'Stop Recording';
      recognizing = true;
    };

    ws.onmessage = evt => {
      transcriptDiv.textContent = JSON.parse(evt.data).transcript;
    };

    ws.onclose = () => {
      processor.disconnect();
      source.disconnect();
      if (audioCtx.state !== 'closed') audioCtx.close();
      startStopBtn.textContent = 'Start Recording';
      recognizing = false;
    };

  } else {
    if (processor) processor.disconnect();
    if (source) source.disconnect();
    if (audioCtx) audioCtx.close();
    if (socket && socket.readyState === WebSocket.OPEN) socket.close();
    recognizing = false;
    startStopBtn.textContent = 'Start Recording';
  }
};
</script>
</body>
</html>
